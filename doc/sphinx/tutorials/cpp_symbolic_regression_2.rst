Find a model including one parameter (using a purely evolutionary approach)
===========================================================================

In this second tutorial we show how to find a model for our input data when we also
want to learn some constants. This case is more generic and interesting than the one treated in the previous tutorial.

Constants can, in general, be learned via two main techniques:
 1. evolutionary (common and standard practice in GP)
 2. memetic (original with dCGP)

The difference is that the evolutionary approach cannot find the correct and exact values for constants, only approximations. 
In this tutorial we follow the evolutionary approach 1. In the next tutorial we will follow a memetic approach 2.
We use the problem P1 from the dcgp::gym, that is x^5 - pi*x^3 + x

Code:
^^^^^^^^
.. literalinclude:: ../../../examples/symbolic_regression_2.cpp
   :language: c++
   :linenos:

Output:
^^^^^^^
Note: the actual output will be different on your computers as its non deterministic.

.. code-block:: python

   Gen:        Fevals:          Best:	Constants:	Formula:
      0              0        3803.05	[1.11378]	[x0 + c1**2] ...
    500           2000         8.2487	[0.959988]	[(-c1 + x0)*x0**4 - x0**2] ...
   1000           4000        2.70799	[1.14114]	[-x0**2*c1 + (-c1 + x0)*x0**4*c1] ...
   1500           6000        2.70797	[1.14053]	[-x0**2*c1 + (-c1 + x0)*x0**4*c1] ...
   2000           8000        2.70796	[1.14064]	[-x0**2*c1 + (-c1 + x0)*x0**4*c1] ...
   2500          10000      0.0901456	[1.0711]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
   3000          12000      0.0597183	[1.07233]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
   3500          14000      0.0597183	[1.07233]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
   4000          16000      0.0597183	[1.07233]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
   4500          18000      0.0596577	[1.0723]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
   5000          20000      0.0596577	[1.0723]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
   5500          22000      0.0596577	[1.0723]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
   6000          24000      0.0596577	[1.0723]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
   6500          26000      0.0596577	[1.0723]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
   7000          28000      0.0596577	[1.0723]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
   7500          30000      0.0596577	[1.0723]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
   8000          32000      0.0596577	[1.0723]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
   8500          34000      0.0596577	[1.0723]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
   9000          36000      0.0596577	[1.0723]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
   9500          38000      0.0596577	[1.0723]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
  10000          40000      0.0596577	[1.0723]	[-x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3] ...
  Exit condition -- generations = 10000

  Best fitness: [0.0596577]
  Chromosome: [1.0723, 1, 0, 0, 2, ... ]
  Pretty Formula: [((((x0*c1)*((x0*c1)*x0))*((x0*c1)*(x0-c1)))-((x0*c1)*((x0*c1)*x0)))]
  Prettier Formula: -x0**3*c1**2 + (-c1 + x0)*x0**4*c1**3
  Expanded Formula: -x0**3*c1**2 - x0**4*c1**4 + x0**5*c1**3
  
